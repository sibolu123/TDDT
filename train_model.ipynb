{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1uuwqjM20R4teBOG4jVcJsgmHKzzTtCWO","authorship_tag":"ABX9TyNIheHQdNRRSMuS4r37XCds"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9_FzH13EjseR","executionInfo":{"status":"ok","timestamp":1612128330372,"user_tz":480,"elapsed":2929,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}}},"source":["%%capture\n","# install dependencies: \n","!pip install pyyaml==5.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-i4hmGYk1dL","executionInfo":{"status":"ok","timestamp":1612128333995,"user_tz":480,"elapsed":6463,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"7e047c91-df50-4ea5-f4d7-ef9ddd643d6b"},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","import torch\n","assert torch.__version__.startswith(\"1.7\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","Collecting detectron2\n","\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/detectron2-0.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n","Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.2.post20210128)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (8.1.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.4.1)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (1.19.5)\n","Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (0.1.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.2)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.32.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.3.3)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.36.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.10.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (51.3.3)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2) (2.2.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.7.4.3)\n","Installing collected packages: detectron2\n","Successfully installed detectron2-0.3+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZyAvNCJMmvFF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612128345229,"user_tz":480,"elapsed":1202,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"2b6e85c0-8f0b-46c1-cb65-f2a1efb5cf04"},"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"execution_count":3,"outputs":[{"output_type":"stream","text":["** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n","** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wWOn_aBVtRzn"},"source":["Use pre-defined model"]},{"cell_type":"code","metadata":{"id":"HUjkwRsOn1O0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612048512863,"user_tz":480,"elapsed":20733,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"8ab3015c-90c4-4c8e-d8ac-21c3cd971453"},"source":["cfg = get_cfg()\n","# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model_final_f10217.pkl: 178MB [00:08, 20.0MB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8IRGo8d0qkgR"},"source":["# We can use `Visualizer` to draw the predictions on the image.\n","def identify(im):\n","  outputs = predictor(im)\n","  v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AiosT9_nvUypm3K0SD8DCfYig4u6cAsA"},"id":"ypwLnwu0THb4","executionInfo":{"status":"ok","timestamp":1612048519954,"user_tz":480,"elapsed":25491,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"2062f649-51ea-4f45-87f8-dae994e7b272"},"source":["im = cv2.imread(\"/content/drive/MyDrive/Scott_Portfolio/traffic_control/frames/frame12s.jpg\")\r\n","identify(im)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"CKrtX5oAtV0f"},"source":["Training customized model for faster speed and particular camera angles"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QNP7nswtCmv","executionInfo":{"status":"ok","timestamp":1612128365052,"user_tz":480,"elapsed":1907,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"8b5ae2ad-549e-4beb-ed32-831cf865a353"},"source":["from detectron2.data.datasets import register_coco_instances\r\n","register_coco_instances(\"data_train\", {}, \"/content/drive/MyDrive/Scott_Portfolio/traffic_control/traffic-4.json\", \"/content/drive/MyDrive/Scott_Portfolio/traffic_control/frames\")\r\n","dataset_dicts = DatasetCatalog.get(\"data_train\")\r\n","car_metadata = MetadataCatalog.get(\"data_train\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[32m[01/31 21:26:06 d2.data.datasets.coco]: \u001b[0mLoading /content/drive/MyDrive/Scott_Portfolio/traffic_control/traffic-4.json takes 1.38 seconds.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/31 21:26:06 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[01/31 21:26:06 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from /content/drive/MyDrive/Scott_Portfolio/traffic_control/traffic-4.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7unkuuiqLdqd","executionInfo":{"status":"ok","timestamp":1612128760710,"user_tz":480,"elapsed":391596,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"9a60fe89-2c9b-4592-fcf5-4c497607f9d4"},"source":["from detectron2.engine import DefaultTrainer\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"data_train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.00025 \n","cfg.SOLVER.MAX_ITER = 650   \n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  #(see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[32m[01/31 21:26:21 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/31 21:26:21 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[01/31 21:26:21 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from /content/drive/MyDrive/Scott_Portfolio/traffic_control/traffic-4.json\n","\u001b[32m[01/31 21:26:21 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 127 images left.\n","\u001b[32m[01/31 21:26:21 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|\n","|    car     | 902          | motorcycle | 217          |\n","|            |              |            |              |\n","|   total    | 1119         |            |              |\u001b[0m\n","\u001b[32m[01/31 21:26:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[01/31 21:26:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[01/31 21:26:21 d2.data.common]: \u001b[0mSerializing 127 elements to byte tensors and concatenating them all ...\n","\u001b[32m[01/31 21:26:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.41 MiB\n"],"name":"stdout"},{"output_type":"stream","text":["model_final_f10217.pkl: 178MB [00:01, 92.5MB/s]                           \n","Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[01/31 21:26:29 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n","/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n","/usr/local/lib/python3.6/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:217: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  num_fg = fg_inds.nonzero().numel()\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[01/31 21:26:44 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 19  total_loss: 2.78  loss_cls: 1.182  loss_box_reg: 0.7795  loss_mask: 0.6896  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.02273  time: 0.7510  data_time: 0.4798  lr: 4.9953e-06  max_mem: 2669M\n","\u001b[32m[01/31 21:27:07 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 39  total_loss: 2.667  loss_cls: 1.104  loss_box_reg: 0.7533  loss_mask: 0.6795  loss_rpn_cls: 0.0942  loss_rpn_loc: 0.02417  time: 0.9523  data_time: 0.8451  lr: 9.9902e-06  max_mem: 2669M\n","\u001b[32m[01/31 21:27:25 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 59  total_loss: 2.426  loss_cls: 0.9936  loss_box_reg: 0.6769  loss_mask: 0.6525  loss_rpn_cls: 0.07798  loss_rpn_loc: 0.02948  time: 0.9314  data_time: 0.5961  lr: 1.4985e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:27:36 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 79  total_loss: 2.287  loss_cls: 0.8591  loss_box_reg: 0.7123  loss_mask: 0.6101  loss_rpn_cls: 0.08629  loss_rpn_loc: 0.0236  time: 0.8334  data_time: 0.0877  lr: 1.998e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:27:46 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 99  total_loss: 2.111  loss_cls: 0.7432  loss_box_reg: 0.7131  loss_mask: 0.5867  loss_rpn_cls: 0.07257  loss_rpn_loc: 0.02645  time: 0.7659  data_time: 0.0052  lr: 2.4975e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:27:56 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 119  total_loss: 2.001  loss_cls: 0.6353  loss_box_reg: 0.6903  loss_mask: 0.5578  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.02795  time: 0.7230  data_time: 0.0052  lr: 2.997e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:28:06 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 139  total_loss: 1.875  loss_cls: 0.5637  loss_box_reg: 0.7306  loss_mask: 0.5093  loss_rpn_cls: 0.05843  loss_rpn_loc: 0.02437  time: 0.6914  data_time: 0.0051  lr: 3.4965e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:28:16 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 159  total_loss: 1.812  loss_cls: 0.5265  loss_box_reg: 0.7282  loss_mask: 0.4681  loss_rpn_cls: 0.05194  loss_rpn_loc: 0.02198  time: 0.6692  data_time: 0.0052  lr: 3.996e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:28:27 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 179  total_loss: 1.716  loss_cls: 0.4754  loss_box_reg: 0.7021  loss_mask: 0.4634  loss_rpn_cls: 0.03915  loss_rpn_loc: 0.02454  time: 0.6521  data_time: 0.0051  lr: 4.4955e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:28:37 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 199  total_loss: 1.558  loss_cls: 0.4414  loss_box_reg: 0.6777  loss_mask: 0.395  loss_rpn_cls: 0.03022  loss_rpn_loc: 0.02337  time: 0.6389  data_time: 0.0050  lr: 4.995e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:28:48 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 219  total_loss: 1.58  loss_cls: 0.4246  loss_box_reg: 0.7009  loss_mask: 0.3938  loss_rpn_cls: 0.03137  loss_rpn_loc: 0.02374  time: 0.6284  data_time: 0.0051  lr: 5.4945e-05  max_mem: 2669M\n","\u001b[32m[01/31 21:28:58 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 239  total_loss: 1.492  loss_cls: 0.3829  loss_box_reg: 0.6631  loss_mask: 0.3754  loss_rpn_cls: 0.02814  loss_rpn_loc: 0.02146  time: 0.6190  data_time: 0.0054  lr: 5.994e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:29:09 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 259  total_loss: 1.407  loss_cls: 0.3692  loss_box_reg: 0.6155  loss_mask: 0.3481  loss_rpn_cls: 0.02651  loss_rpn_loc: 0.02495  time: 0.6111  data_time: 0.0054  lr: 6.4935e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:29:19 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 279  total_loss: 1.366  loss_cls: 0.3438  loss_box_reg: 0.6357  loss_mask: 0.3167  loss_rpn_cls: 0.02452  loss_rpn_loc: 0.02244  time: 0.6048  data_time: 0.0053  lr: 6.993e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:29:30 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 299  total_loss: 1.259  loss_cls: 0.3161  loss_box_reg: 0.5902  loss_mask: 0.2865  loss_rpn_cls: 0.0221  loss_rpn_loc: 0.019  time: 0.5997  data_time: 0.0052  lr: 7.4925e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:29:40 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 319  total_loss: 1.225  loss_cls: 0.308  loss_box_reg: 0.5838  loss_mask: 0.2929  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.0218  time: 0.5954  data_time: 0.0051  lr: 7.992e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:29:51 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 339  total_loss: 1.169  loss_cls: 0.2925  loss_box_reg: 0.5646  loss_mask: 0.2962  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.02035  time: 0.5921  data_time: 0.0051  lr: 8.4915e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:30:02 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 359  total_loss: 1.111  loss_cls: 0.2922  loss_box_reg: 0.5223  loss_mask: 0.2587  loss_rpn_cls: 0.01691  loss_rpn_loc: 0.02919  time: 0.5884  data_time: 0.0050  lr: 8.991e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:30:12 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 379  total_loss: 1.02  loss_cls: 0.2614  loss_box_reg: 0.4244  loss_mask: 0.2407  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.01765  time: 0.5862  data_time: 0.0053  lr: 9.4905e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:30:24 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 399  total_loss: 0.9917  loss_cls: 0.2584  loss_box_reg: 0.4088  loss_mask: 0.2431  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.02682  time: 0.5844  data_time: 0.0052  lr: 9.99e-05  max_mem: 2670M\n","\u001b[32m[01/31 21:30:34 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 419  total_loss: 0.8455  loss_cls: 0.2456  loss_box_reg: 0.3378  loss_mask: 0.2223  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.0216  time: 0.5818  data_time: 0.0054  lr: 0.0001049  max_mem: 2670M\n","\u001b[32m[01/31 21:30:45 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 439  total_loss: 0.8219  loss_cls: 0.2133  loss_box_reg: 0.3785  loss_mask: 0.202  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.02315  time: 0.5801  data_time: 0.0050  lr: 0.00010989  max_mem: 2670M\n","\u001b[32m[01/31 21:30:56 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 459  total_loss: 0.7791  loss_cls: 0.207  loss_box_reg: 0.3568  loss_mask: 0.1896  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.01983  time: 0.5784  data_time: 0.0051  lr: 0.00011489  max_mem: 2670M\n","\u001b[32m[01/31 21:31:07 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 479  total_loss: 0.7885  loss_cls: 0.2141  loss_box_reg: 0.3444  loss_mask: 0.1962  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.02316  time: 0.5765  data_time: 0.0049  lr: 0.00011988  max_mem: 2670M\n","\u001b[32m[01/31 21:31:17 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 499  total_loss: 0.6693  loss_cls: 0.1772  loss_box_reg: 0.2481  loss_mask: 0.1965  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.0226  time: 0.5749  data_time: 0.0052  lr: 0.00012488  max_mem: 2670M\n","\u001b[32m[01/31 21:31:28 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 519  total_loss: 0.7007  loss_cls: 0.202  loss_box_reg: 0.2737  loss_mask: 0.193  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.02347  time: 0.5734  data_time: 0.0053  lr: 0.00012987  max_mem: 2670M\n","\u001b[32m[01/31 21:31:39 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 539  total_loss: 0.6561  loss_cls: 0.1769  loss_box_reg: 0.2667  loss_mask: 0.1664  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.02013  time: 0.5724  data_time: 0.0053  lr: 0.00013487  max_mem: 2670M\n","\u001b[32m[01/31 21:31:50 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 559  total_loss: 0.6378  loss_cls: 0.171  loss_box_reg: 0.2324  loss_mask: 0.1614  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.01731  time: 0.5714  data_time: 0.0052  lr: 0.00013986  max_mem: 2670M\n","\u001b[32m[01/31 21:32:01 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 579  total_loss: 0.6484  loss_cls: 0.1635  loss_box_reg: 0.2932  loss_mask: 0.1713  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.02126  time: 0.5704  data_time: 0.0051  lr: 0.00014486  max_mem: 2670M\n","\u001b[32m[01/31 21:32:12 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 599  total_loss: 0.6133  loss_cls: 0.1766  loss_box_reg: 0.2332  loss_mask: 0.155  loss_rpn_cls: 0.008369  loss_rpn_loc: 0.02021  time: 0.5699  data_time: 0.0051  lr: 0.00014985  max_mem: 2670M\n","\u001b[32m[01/31 21:32:23 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 619  total_loss: 0.7328  loss_cls: 0.1531  loss_box_reg: 0.2973  loss_mask: 0.192  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.02329  time: 0.5690  data_time: 0.0055  lr: 0.00015485  max_mem: 2670M\n","\u001b[32m[01/31 21:32:34 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 639  total_loss: 0.5551  loss_cls: 0.1666  loss_box_reg: 0.2194  loss_mask: 0.1432  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.0161  time: 0.5684  data_time: 0.0051  lr: 0.00015984  max_mem: 2670M\n","\u001b[32m[01/31 21:32:41 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 649  total_loss: 0.5878  loss_cls: 0.1748  loss_box_reg: 0.2191  loss_mask: 0.1546  loss_rpn_cls: 0.00915  loss_rpn_loc: 0.01901  time: 0.5681  data_time: 0.0049  lr: 0.00016234  max_mem: 2670M\n","\u001b[32m[01/31 21:32:41 d2.engine.hooks]: \u001b[0mOverall training speed: 648 iterations in 0:06:08 (0.5681 s / it)\n","\u001b[32m[01/31 21:32:41 d2.engine.hooks]: \u001b[0mTotal training time: 0:06:10 (0:00:02 on hooks)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xt20DaHKRcRR"},"source":["Run the model on some random pictures and check accuracy"]},{"cell_type":"code","metadata":{"id":"Ya5nEuMELeq8","executionInfo":{"status":"ok","timestamp":1612128853933,"user_tz":480,"elapsed":1348,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}}},"source":["# Inference should use the config with parameters that are used in training\n","# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n","predictor = DefaultPredictor(cfg)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1tkWVj6w5Cy2vR1xuNNkJyPv0vBSbrIa3"},"id":"U5LhISJqWXgM","executionInfo":{"status":"ok","timestamp":1612128885581,"user_tz":480,"elapsed":25716,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}},"outputId":"e9629f39-3197-48d0-9738-13257a8c164c"},"source":["from detectron2.utils.visualizer import ColorMode\n","for d in random.sample(dataset_dicts, 10):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=car_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n","    )\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"g7UnV5bZRTI3"},"source":["Save the model to folder"]},{"cell_type":"code","metadata":{"id":"gq9RWI5AQnlK","executionInfo":{"status":"ok","timestamp":1612129380909,"user_tz":480,"elapsed":2521,"user":{"displayName":"Scott","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoWusH5yuxnGo-UTuPvTYnYi3rLVvzxSHQWBZleg=s64","userId":"02557000719248032233"}}},"source":["from detectron2.checkpoint import DetectionCheckpointer\r\n","from detectron2.modeling import build_model\r\n","model = build_model(cfg)  # returns a torch.nn.Module\r\n","\r\n","DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)  # load a file, usually from cfg.MODEL.WEIGHTS\r\n","checkpointer = DetectionCheckpointer(model, save_dir=\"/content/drive/MyDrive/Scott_Portfolio/traffic_control\")\r\n","checkpointer.save(\"model_650\")  # save weights"],"execution_count":10,"outputs":[]}]}